{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">YOLOv5 model 🤖</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, you can train and make predictions using YOLOv5 on my dataset. 🚗🅿️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.functions import is_custom_model\n",
    "\n",
    "repo_path = os.getcwd()\n",
    "repo_path = os.path.dirname(repo_path)\n",
    "\n",
    "yolov5_path = os.path.join(repo_path, 'yolov5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'c:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\yolov5' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo path: c:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\n",
      "Yolo path: c:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\yolov5\n",
      "Data copied to c:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\yolov5\\data/custom-data ✅\n",
      "Dataset split into train and val sets ✅\n",
      "Only car labels left ✅\n"
     ]
    }
   ],
   "source": [
    "# notebook git clone yolov5\n",
    "!git clone https://github.com/ultralytics/yolov5.git $yolov5_path\n",
    "\n",
    "# copy data to yolov5/data/custom-data\n",
    "!python $repo_path/utils/yolov5start.py --reporoot $repo_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\yolov5\n",
      "Requirement already satisfied: gitpython>=3.1.30 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 5)) (3.1.31)\n",
      "Requirement already satisfied: matplotlib>=3.3 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 7)) (1.25.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 9)) (9.5.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 13)) (1.10.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 15)) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 16)) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
      "Requirement already satisfied: ultralytics>=8.0.111 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 18)) (8.0.120)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 27)) (2.0.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from -r requirements.txt (line 42)) (68.0.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.10)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.40.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.5.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.6.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (1.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 15)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mathe\\documents\\projects\\yolo-parking-spot\\env\\lib\\site-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 15)) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%cd $yolov5_path\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda:0\" \n",
    "else: \n",
    "    dev = \"cpu\" \n",
    "device = torch.device(dev) \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolov5_train(model, device=\"cpu\"):\n",
    "    model, model_path = is_custom_model(model, \"5\")\n",
    "\n",
    "    !python train.py \\\n",
    "        --weights \"{model_path}\" \\\n",
    "        --img 1920 \\\n",
    "        --data \"{yolov5_path}/data/custom-data/dataset.yaml\" \\\n",
    "        --epochs 200 \\\n",
    "        --batch 2 \\\n",
    "        --project \"{repo_path}/models/{model[:-3]}\" \\\n",
    "        --device \"{device}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolov5_detect(model, device=\"cpu\", conf=0.25):\n",
    "    model, model_path = is_custom_model(model, \"5\")\n",
    "    \n",
    "    # Remove folder if it exists\n",
    "    if os.path.exists(os.path.join(repo_path, f'results/{model[:-3]}/')):\n",
    "        shutil.rmtree(os.path.join(repo_path, f'results/{model[:-3]}/'))\n",
    "    \n",
    "\n",
    "    # \n",
    "    !python detect.py \\\n",
    "        --img 1920 \\\n",
    "        --source \"{repo_path}/data/images\" \\\n",
    "        --weights \"{model_path}\" \\\n",
    "        --conf {conf} \\\n",
    "        --iou 0.05 \\\n",
    "        --nosave \\\n",
    "        --save-txt \\\n",
    "        --project \"{repo_path}/results\" \\\n",
    "        --name \"{model[:-3]}\" \\\n",
    "        --device \"{device}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Train your own YOLOv5 model on my dataset 🤖🚗🅿️</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "To get started, simply call the `yolov5_train(model, device)` function. The `device` parameter specifies what device you want to use (cuda device, i.e. 0 or 0,1,2,3 or cpu), the `model` parameter specifies the model configuration you want to use. There are three options available:\n",
    "\n",
    "### 1. Standard YOLOv5 Model\n",
    "You can use one of the pre-trained standard YOLOv5 models by providing the model name. For example:\n",
    "```python\n",
    "yolov5_train('yolov5n')\n",
    "```\n",
    "This will use the 'yolov5n' model for object detection and training. For more information on the available standard YOLOv5 models, you can refer to the [YOLOv5 models](https://github.com/ultralytics/yolov5#pretrained-checkpoints) repository.\n",
    "\n",
    "### 2. Custom Model\n",
    "If you want to train a custom model, you can provide the path to the model weights file. For example:\n",
    "```python\n",
    "yolov5_train(f'{repo_path}/models/yolov5n/exp/weights/best.pt')\n",
    "```\n",
    "This will allow you to train your own YOLOv5 model using the specified weights.\n",
    "\n",
    "### 3. Uploaded Model\n",
    "If you manually added a model to the models folder and want to train using that model, you can provide the name of the model file. For example:\n",
    "```python\n",
    "yolov5_train('my_yolov5n.pt')\n",
    "```\n",
    "This will use the 'my_yolov5n.pt' model for object detection and training.\n",
    "\n",
    "## Customizing Training Arguments\n",
    "\n",
    "If you want to customize the training arguments, you can modify the `yolov5_train(model)` function. The function takes care of the object detection and training process, but you can explore and modify the code inside the function according to your specific needs.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want to train, just uncomment the following lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name:\n",
    "#yolov5_train('yolov5n.pt')\n",
    "\n",
    "# path:\n",
    "#yolov5_train(f'{repo_path}/models/yolov5n/exp/weights/best.pt')\n",
    "\n",
    "# uploaded model:\n",
    "#yolov5_train('my_yolov5n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Make predictions with your own YOLOv5 model on my dataset 🔮🚗🔍</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "To get started, simply call the `yolov5_detect(model, device)` function. The `device` parameter specifies what device you want to use (cuda device, i.e. 0 or 0,1,2,3 or cpu), the `model` parameter specifies the model configuration you want to use. There are three options available:\n",
    "\n",
    "### 1. Standard YOLOv5 Model\n",
    "You can use one of the pre-trained standard YOLOv5 models by providing the model name. For example:\n",
    "```python\n",
    "yolov5_detect('yolov5n')\n",
    "```\n",
    "This will use the 'yolov5n' model for object detection and prediction. For more information on the available standard YOLOv5 models, you can refer to the [YOLOv8 models](https://github.com/ultralytics/yolov5#pretrained-checkpoints) repository.\n",
    "\n",
    "### 2. Custom Model\n",
    "If you want to make predictions with a custom model, you can provide the path to the model weights file. For example:\n",
    "```python\n",
    "yolov5_detect(f'{repo_path}/models/yolov5n/exp/weights/best.pt')\n",
    "```\n",
    "This will allow you to make predictions on my dataset using the specified weights.\n",
    "\n",
    "### 3. Uploaded Model\n",
    "If you manually added a model to the models folder and want to make predictions using that model, you can provide the name of the model file. For example:\n",
    "```python\n",
    "yolov5_detect('my_yolov5n.pt')\n",
    "```\n",
    "This will use the 'my_yolov5n.pt' model for object prediction.\n",
    "\n",
    "## Customizing Prediction Arguments\n",
    "\n",
    "If you want to customize the prediction arguments, you can modify the `yolov5_detect(model)` function. The function takes care of the object detection and prediction process, but you can explore and modify the code inside the function according to your specific needs.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want to train, just uncomment the following lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['c:\\\\Users\\\\mathe\\\\Documents\\\\Projects\\\\YOLO-Parking-Spot\\\\models/my_yolov5s.pt'], source=c:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot/data/images, data=data\\coco128.yaml, imgsz=[1920, 1920], conf_thres=0.4, iou_thres=0.05, max_det=1000, device=cpu, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=True, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=c:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot/results, name=my_yolov5s, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v7.0-185-g2334aa7 Python-3.10.11 torch-2.0.1+cu118 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\empty_set1_60m_1.jpg: 1088x1920 1 car, 1039.1ms\n",
      "image 2/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\empty_set1_60m_2.jpg: 1088x1920 1 car, 963.9ms\n",
      "image 3/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\empty_set1_65m_1.jpg: 1088x1920 (no detections), 877.3ms\n",
      "image 4/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\empty_set1_70m_2.jpg: 1088x1920 1 car, 847.5ms\n",
      "image 5/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\empty_set1_75m_1.jpg: 1088x1920 (no detections), 840.8ms\n",
      "image 6/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\empty_set2_30m_2.jpg: 1088x1920 (no detections), 893.6ms\n",
      "image 7/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\empty_set2_30m_3.jpg: 1088x1920 (no detections), 911.0ms\n",
      "image 8/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\empty_set2_70m_1.jpg: 1088x1920 (no detections), 882.5ms\n",
      "image 9/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\empty_set2_70m_2.jpg: 1088x1920 (no detections), 919.2ms\n",
      "image 10/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set1_30m_1.jpg: 1088x1920 15 cars, 882.0ms\n",
      "image 11/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set1_30m_2.jpg: 1088x1920 15 cars, 859.3ms\n",
      "image 12/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set1_40m_1.jpg: 1088x1920 44 cars, 890.2ms\n",
      "image 13/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set1_50m_1.jpg: 1088x1920 52 cars, 889.0ms\n",
      "image 14/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set1_50m_2.jpg: 1088x1920 52 cars, 867.2ms\n",
      "image 15/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set1_60m_1.jpg: 1088x1920 58 cars, 876.3ms\n",
      "image 16/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set1_70m_1.jpg: 1088x1920 60 cars, 875.5ms\n",
      "image 17/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set1_70m_2.jpg: 1088x1920 60 cars, 881.1ms\n",
      "image 18/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set2_30m_1.jpg: 1088x1920 14 cars, 880.1ms\n",
      "image 19/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set2_30m_2.jpg: 1088x1920 14 cars, 903.8ms\n",
      "image 20/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set2_40m_1.jpg: 1088x1920 19 cars, 874.9ms\n",
      "image 21/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set2_50m_1.jpg: 1088x1920 19 cars, 902.8ms\n",
      "image 22/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set2_60m_1.jpg: 1088x1920 30 cars, 903.2ms\n",
      "image 23/23 C:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\data\\images\\occupied_set2_70m_1.jpg: 1088x1920 32 cars, 881.6ms\n",
      "Speed: 9.3ms pre-process, 893.1ms inference, 1.6ms NMS per image at shape (1, 3, 1920, 1920)\n",
      "Results saved to \u001b[1mc:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\results\\my_yolov5s\u001b[0m\n",
      "17 labels saved to c:\\Users\\mathe\\Documents\\Projects\\YOLO-Parking-Spot\\results\\my_yolov5s\\labels\n"
     ]
    }
   ],
   "source": [
    "# name:\n",
    "#yolov5_detect('yolov5n.pt')\n",
    "\n",
    "# path:\n",
    "#yolov5_detect(f'{repo_path}/models/yolov5n/exp/weights/best.pt')\n",
    "\n",
    "# uploaded model:\n",
    "#yolov5_detect('my_yolov5s.pt', conf=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Comparing the YOLOv5 models</div>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
