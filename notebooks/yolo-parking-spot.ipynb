{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_occupied(image, annotations, left, top, right, bottom, threshold):\n",
    "    # Get the car bounding boxes\n",
    "    car_boxes = []\n",
    "    for annotation in annotations:\n",
    "        class_id, x_center, y_center, width, height = map(float, annotation.split())\n",
    "        if class_id == 4:\n",
    "            car_left = int((x_center - width / 2) * image.shape[1])\n",
    "            car_top = int((y_center - height / 2) * image.shape[0])\n",
    "            car_right = int((x_center + width / 2) * image.shape[1])\n",
    "            car_bottom = int((y_center + height / 2) * image.shape[0])\n",
    "            car_boxes.append((car_left, car_top, car_right, car_bottom))\n",
    "    \n",
    "    # If there are no cars in the image that intersect with the parking spot, return False\n",
    "    if not car_boxes:\n",
    "        return False\n",
    "    \n",
    "    # Calculate the intersection over union (IoU) between the parking spot and each car\n",
    "    ious = []\n",
    "    for car_box in car_boxes:\n",
    "        intersection_left = max(left, car_box[0])\n",
    "        intersection_top = max(top, car_box[1])\n",
    "        intersection_right = min(right, car_box[2])\n",
    "        intersection_bottom = min(bottom, car_box[3])\n",
    "        intersection_area = max(0, intersection_right - intersection_left) * max(0, intersection_bottom - intersection_top)\n",
    "        parking_spot_area = (right - left) * (bottom - top)\n",
    "        car_area = (car_box[2] - car_box[0]) * (car_box[3] - car_box[1])\n",
    "        iou = intersection_area / (parking_spot_area + car_area - intersection_area)\n",
    "        ious.append(iou)\n",
    "    \n",
    "    # Return True if the maximum IoU is above the threshold, False otherwise\n",
    "    return np.max(ious) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Function to draw bounding boxes on the image\n",
    "def draw_bounding_boxes(image_path, annotation_path, output_path, threshold, highlighted_cars):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Read the annotation file\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        annotations = f.readlines()\n",
    "    \n",
    "    # Create a dictionary to store the class counts\n",
    "    class_counts = {}\n",
    "    disabled_spot_occupied = 0\n",
    "    spot_occupied = 0\n",
    "    \n",
    "    # Process each annotation and store rectangle information in a list\n",
    "    rectangles = []\n",
    "    for annotation in annotations:\n",
    "        # Parse the annotation values\n",
    "        class_id, x_center, y_center, width, height = map(float, annotation.split())\n",
    "\n",
    "        # Calculate the bounding box coordinates\n",
    "        left = int((x_center - width / 2) * image.shape[1])\n",
    "        top = int((y_center - height / 2) * image.shape[0])\n",
    "        right = int((x_center + width / 2) * image.shape[1])\n",
    "        bottom = int((y_center + height / 2) * image.shape[0])\n",
    "\n",
    "\n",
    "        # Increment the class count\n",
    "        class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
    "\n",
    "        # Set the color based on the class ID\n",
    "        if class_id == 4: # Car\n",
    "            if highlighted_cars:\n",
    "                color = (0, 165, 255)  # Orange color\n",
    "            else:\n",
    "                continue\n",
    "        elif class_id == 15: # Disabled parking spot\n",
    "            # Check if there is a car occupying of the parking spot\n",
    "            if is_occupied(image, annotations, left, top, right, bottom, threshold):\n",
    "                disabled_spot_occupied += 1\n",
    "                color = (0, 0, 255)  # Red color\n",
    "            else:\n",
    "                color = (255, 0, 0)  # Blue color\n",
    "        elif class_id == 16: # Parking spot\n",
    "            # Check if there is a car occupying the parking spot\n",
    "            if is_occupied(image, annotations, left, top, right, bottom, threshold):\n",
    "                spot_occupied += 1\n",
    "                color = (0, 0, 255)  # Red color\n",
    "            else:\n",
    "                color = (0, 255, 0)  # Green color\n",
    "\n",
    "        # Store the rectangle information in the list\n",
    "        rectangles.append((left, top, right, bottom, color))\n",
    "\n",
    "    # Sort the rectangles list based on class_id, so that red rectangles are processed last\n",
    "    rectangles.sort(key=lambda x: x[4] == (0, 0, 255))\n",
    "\n",
    "    # Draw the bounding box rectangles on the image\n",
    "    for rectangle in rectangles:\n",
    "        left, top, right, bottom, color = rectangle\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), color, 2)\n",
    "\n",
    "    alpha = 0.4  # Transparency factor.\n",
    "    \n",
    "    # Image legend\n",
    "    text_position = (image.shape[1] - 400, 30)  # Top-right corner position\n",
    "    overlay = image.copy()\n",
    "    cv2.rectangle(overlay, (text_position[0] - 10, text_position[1] - 30), (text_position[0] + 390, text_position[1] + 80), (0, 0, 0), cv2.FILLED)\n",
    "    image = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0) # Add the overlay to the image\n",
    "    \n",
    "    text = f'Disabled parking spots Count: {class_counts.get(15, 0)}'\n",
    "    cv2.putText(image, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    text_position = (text_position[0], text_position[1] + 30)  # Increment the y-coordinate\n",
    "    \n",
    "    text = f'Parking spots Count: {class_counts.get(16, 0)}'\n",
    "    cv2.putText(image, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    text_position = (text_position[0], text_position[1] + 30)  # Increment the y-coordinate\n",
    "\n",
    "    text = f'Cars count: {class_counts.get(4, 0)}'\n",
    "    cv2.putText(image, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    \n",
    "    text_position = (30, 30)  # Top-left corner position\n",
    "    overlay = image.copy()\n",
    "    cv2.rectangle(overlay, (text_position[0] - 10, text_position[1] - 30), (text_position[0] + 575, text_position[1] + 140), (0, 0, 0, 0.8), cv2.FILLED)\n",
    "    image = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0) # Add the overlay to the image\n",
    "\n",
    "    text = f'Empty disabled parking spots Count: {class_counts.get(15, 0) - disabled_spot_occupied}'\n",
    "    cv2.putText(image, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    text_position = (text_position[0], text_position[1] + 30)  # Increment the y-coordinate\n",
    "\n",
    "    text = f'Occupied disabled parking spots Count: {disabled_spot_occupied}'\n",
    "    cv2.putText(image, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    text_position = (text_position[0], text_position[1] + 30)  # Increment the y-coordinate\n",
    "\n",
    "    text = f'Empty parking spots Count: {class_counts.get(16, 0) - spot_occupied}'\n",
    "    cv2.putText(image, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    text_position = (text_position[0], text_position[1] + 30)  # Increment the y-coordinate\n",
    "\n",
    "    text = f'Occupied parking spots count: {spot_occupied}'\n",
    "    cv2.putText(image, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    text_position = (text_position[0], text_position[1] + 30)  # Increment the y-coordinate\n",
    "\n",
    "    text = f'Cars in transit or parked in non-parking spots: {class_counts.get(4, 0) - disabled_spot_occupied - spot_occupied}'\n",
    "    cv2.putText(image, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    \n",
    "    # Save the image with bounding boxes\n",
    "    output_image_path = os.path.join(output_path, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_image_path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(folder_path, output_folder, threshold=0.4, highlighted_cars=True):\n",
    "    processed_images = 0\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Process each image and annotation in the folder\n",
    "    for image_file in os.listdir(folder_path):\n",
    "        if image_file.endswith('.jpg'):  # Assuming image files have the .jpg extension\n",
    "            # Get the paths for the current image and its corresponding annotation file\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            annotation_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "            annotation_path = os.path.join(folder_path, annotation_file)\n",
    "            \n",
    "            # Call the function to draw bounding boxes and save the resulting image\n",
    "            draw_bounding_boxes(image_path, annotation_path, output_folder, threshold, highlighted_cars)\n",
    "            processed_images += 1\n",
    "\n",
    "    print(f'Processed {processed_images} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14 images\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path containing the images and annotations\n",
    "folder_path = '../data/imgs/occupied'\n",
    "\n",
    "# Specify the output folder path\n",
    "output_folder = '../result/imgs/occupied_with_boxes'\n",
    "\n",
    "process_images(folder_path, output_folder, highlighted_cars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9 images\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path containing the images and annotations\n",
    "folder_path = '../data/imgs/empty'\n",
    "\n",
    "# Specify the output folder path\n",
    "output_folder = '../result/imgs/empty_with_boxes'\n",
    "\n",
    "process_images(folder_path, output_folder, highlighted_cars=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
